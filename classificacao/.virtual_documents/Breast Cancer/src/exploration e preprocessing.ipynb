# libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


# load data
df = pd.read_csv('../data/cancer.csv', sep=',', encoding='utf-8')


# head data
df.head()


# tail data
df.tail()


# info data


df.info()


# NaN
df.isna().sum()


# duplicates
df.duplicated().any()


# types
df.dtypes


# shape
df.shape


# drop features
df2 = df.drop(['id', 'Unnamed: 32'], axis=1)
df2


# describe
df2.describe().T


# feat: diagnosis
df2.diagnosis.value_counts()


# plot
sns.countplot(x='diagnosis', data=df2);


# hist
df2.hist(figsize=(15,15));


# função para encontrar outliers
def count_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers


# outliers
for col in df2.select_dtypes(include=np.number).columns:
    print("{:<15} {:>6}".format(col, len(count_outliers(df2, col))))


# corr
df2.corr()['diagnosis'].sort_values(ascending=False)


# mapa de correlacoes com mascara
corr = df2.corr()
mask = np.triu(np.ones_like(corr, dtype=bool))  # mascara para o triangulo superior

plt.figure(figsize=(20, 12))
sns.heatmap(corr, mask=mask, linewidths=1, annot=True, fmt=".2f", cmap="coolwarm")
plt.show()


# encoding diagnosis
df2.diagnosis.replace({'M': 1, 'B': 0}, inplace=True)
df2.diagnosis.value_counts()


df2.head()


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


# alvo e previsores
X = df2.drop(['diagnosis'], axis=1)
y = df2['diagnosis']


# escalonado
scaler= StandardScaler()
X_esc = scaler.fit_transform(X)  


X.head()


X_esc


y.values


previsores = {'original':X, 'escalonado': X_esc}
dados_previsores = {}
for nome, previsor in previsores.items():
    x_train, x_test, y_train, y_test = train_test_split(previsor, y, test_size=0.3, random_state=0)
    dados_previsores[f'x_train_{nome}'] = x_train
    dados_previsores[f'x_test_{nome}'] = x_test
    dados_previsores[f'y_train_{nome}'] = y_train
    dados_previsores[f'y_test_{nome}'] = y_test


dados_previsores.keys()


dados_previsores['x_train_original'].head()


dados_previsores['x_train_escalonado']


from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score,classification_report
from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold

import warnings
warnings.filterwarnings("ignore")


# função para treinar avaliar um modelo

def treinar_e_avaliar_modelo(clf, nome_modelo, dados, previsores, alvo):
    """
    Treina, avalia o modelo para cada conjunto de previsores e realiza cross-validation.
    Retorna um DataFrame com as principais métricas (acurácia de treino, teste, validação cruzada, etc.).
    """
    resultados = [] 

    for nome, df in previsores.items():
        x_train = dados[f'x_train_{nome}']
        y_train = dados[f'y_train_{nome}']
        x_test = dados[f'x_test_{nome}']
        y_test = dados[f'y_test_{nome}']

        # treino
        clf.fit(x_train, y_train)
        y_pred = clf.predict(x_test)

        # metricas
        acuracia_teste = accuracy_score(y_test, y_pred)
        acuracia_treino = clf.score(x_train, y_train)
        matriz_confusao = confusion_matrix(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)

        # validação cruzada
        cv_scores = cross_val_score(clf, df, alvo, cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=8))
        acuracia_cv = cv_scores.mean() * 100

        # Registro dos resultados
        resultados.append({
            'modelo': nome_modelo,
            'conjunto': nome,
            'acuracia_teste': acuracia_teste * 100,
            'acuracia_treino': acuracia_treino * 100,
            'acuracia_cv': acuracia_cv,
            'precision': report['weighted avg']['precision'] * 100,
            'recall': report['weighted avg']['recall'] * 100,
            'f1_score': report['weighted avg']['f1-score'] * 100,
            'matriz_confusao': matriz_confusao.tolist()
        })

    return pd.DataFrame(resultados)


# naive bayes
naive = GaussianNB()
resultados_naive_bayes = treinar_e_avaliar_modelo(clf=naive, nome_modelo="Naive Bayes", dados=dados_previsores, previsores=previsores, alvo=y)
resultados_naive_bayes


# svm
svm = SVC(random_state=0)

param_grid = dict(
    kernel = ['linear','rbf','poly', 'sigmoid'],
    C =[1,2,3,4,5],
    gamma=['scale','auto']
)

grid_search = GridSearchCV(svm, param_grid,scoring='roc_auc',cv=4, verbose=1)
grid_search.fit(dados_previsores['x_train_escalonado'], dados_previsores['y_train_escalonado'])
best_params = grid_search.best_params_

svm_best = SVC(random_state=0, **best_params)
resultados_svm = treinar_e_avaliar_modelo(clf=svm_best, nome_modelo='SVM', dados=dados_previsores, previsores=previsores, alvo=y)
resultados_svm


# gradient boosting
gbm = GradientBoostingClassifier(random_state=0)

param_grid = dict(
    n_estimators=[20, 50, 100, 250],
    learning_rate=[0.05, 0.1, 0.5],
    max_depth=[1,2,3,4,5],
    )

grid_search = GridSearchCV(gbm, param_grid, scoring='roc_auc', cv=4)
grid_search.fit(dados_previsores['x_train_escalonado'], dados_previsores['y_train_escalonado'])
best_params = grid_search.best_params_

gbm_best = GradientBoostingClassifier(random_state=0, **best_params)
resultados_gbm = treinar_e_avaliar_modelo(clf=gbm_best, nome_modelo='Gradient Boosting', dados=dados_previsores, previsores=previsores, alvo=y)
resultados_gbm


# regressao logistica
reg_log = LogisticRegression(random_state=0)

param_grid = dict(
    max_iter = [100, 200, 500, 1000, 2000],
    penalty = ['l1', 'l2', 'elasticnet', None],
    tol = [0.0001, 0.001,0.01,0.00001],
    C=[1,2,3,4,5],
    solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']
)

grid_search = GridSearchCV(reg_log, param_grid, scoring='roc_auc', cv=4)
grid_search.fit(dados_previsores['x_train_escalonado'], dados_previsores['y_train_escalonado'])
best_params = grid_search.best_params_

reg_log_best = LogisticRegression(random_state=0, **best_params)
resultados_regressao_logistica = treinar_e_avaliar_modelo(clf=reg_log_best, nome_modelo='Logistic Regression', dados=dados_previsores, previsores=previsores, alvo=y)
resultados_regressao_logistica





















