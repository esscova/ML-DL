# packages
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from xgboost import XGBClassifier


# carregar os dados
alvo = np.genfromtxt('../data/heart_target.csv', delimiter=',', encoding='utf-8')
previsores = {
    "label_encoded": pd.read_csv('../data/heart_predictor_le.csv', sep=',', encoding='utf-8'),
    "one_hot_encoded": pd.read_csv('../data/heart_predictor_ohe.csv', sep=',', encoding='utf-8'),
    "escalonado": pd.read_csv('../data/heart_predictor_esc.csv', sep=',', encoding='utf-8')
}


# bases de treino e teste
def separar_bases(previsores, alvo):
    data = {}
    for nome, df in previsores.items():
        x_train, x_test, y_train, y_test = train_test_split(df.values, alvo, test_size=0.3, random_state=83)
        data[f'x_train_{nome}'] = x_train
        data[f'x_test_{nome}'] = x_test
        data[f'y_train_{nome}'] = y_train
        data[f'y_test_{nome}'] = y_test
    return data

dados = separar_bases(previsores, alvo)


# função para treinar avaliar um modelo

def treinar_e_avaliar_modelo(clf, nome_modelo, dados, previsores, alvo, cv_splits):
    """
    Treina, avalia o modelo para cada conjunto de previsores e realiza cross-validation.
    Retorna um DataFrame com as principais métricas (acurácia de treino, teste, validação cruzada, etc.).
    """
    resultados = [] 

    for nome, df in previsores.items():
        x_train = dados[f'x_train_{nome}']
        y_train = dados[f'y_train_{nome}']
        x_test = dados[f'x_test_{nome}']
        y_test = dados[f'y_test_{nome}']

        # treino
        clf.fit(x_train, y_train)
        y_pred = clf.predict(x_test)

        # metricas
        acuracia_teste = accuracy_score(y_test, y_pred)
        acuracia_treino = clf.score(x_train, y_train)
        matriz_confusao = confusion_matrix(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)

        # validação cruzada
        cv_scores = cross_val_score(clf, df, alvo, cv=StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=8))
        acuracia_cv = cv_scores.mean() * 100

        # Registro dos resultados
        resultados.append({
            'modelo': nome_modelo,
            'conjunto': nome,
            'acuracia_teste': acuracia_teste * 100,
            'acuracia_treino': acuracia_treino * 100,
            'acuracia_cv': acuracia_cv,
            'precision': report['weighted avg']['precision'] * 100,
            'recall': report['weighted avg']['recall'] * 100,
            'f1_score': report['weighted avg']['f1-score'] * 100,
            'matriz_confusao': matriz_confusao.tolist()
        })

    return pd.DataFrame(resultados)


# naive bayes
naive = GaussianNB()
resultados_naive_bayes = treinar_e_avaliar_modelo(naive, "Naive Bayes", dados, previsores, alvo, 20)
resultados_naive_bayes


# svm
svm = SVC(kernel='rbf', random_state=1, C=2)
resultados_svm = treinar_e_avaliar_modelo(svm, "SVM", dados, previsores, alvo, 20)
resultados_svm


# regressao logistica
reg_log =  LogisticRegression(random_state=1, max_iter=2000, penalty="l2", tol=0.0001, C=1, solver="lbfgs")
resultados_regressao_logistica = treinar_e_avaliar_modelo(reg_log, "Logistic Regression", dados, previsores, alvo, 20)
resultados_regressao_logistica


# knn
knn =  KNeighborsClassifier(n_neighbors=7, metric='minkowski', p=1)
resultados_knn = treinar_e_avaliar_modelo(knn, "KNN", dados, previsores, alvo, 20)
resultados_knn


# arvores de decisao
tree =  DecisionTreeClassifier(criterion='entropy', random_state = 0, max_depth=3)
resultados_tree = treinar_e_avaliar_modelo(tree, "Tree", dados, previsores, alvo, 20)
resultados_tree


# random forest
random_for = RandomForestClassifier(n_estimators=150, criterion='entropy', random_state = 0, max_depth=4)
resultados_random_forest = treinar_e_avaliar_modelo(random_for, "Random Forest", dados, previsores, alvo, 20)
resultados_random_forest


# xgboost
xgboost = XGBClassifier(max_depth=2, learning_rate=0.05, n_estimators=250, objective='binary:logistic', random_state=3)
resultados_xgboost = treinar_e_avaliar_modelo(xgboost, "XGBoost", dados, previsores, alvo, 8)
resultados_xgboost


# metricas de todos os modelos
resultados = pd.concat([resultados_knn, 
                        resultados_naive_bayes, 
                        resultados_random_forest, 
                        resultados_regressao_logistica, 
                        resultados_svm, 
                        resultados_tree, 
                        resultados_xgboost], 
                       ignore_index=True)

resultados['dif_acuracia_treino_teste'] = resultados['acuracia_treino'] - resultados['acuracia_teste']
resultados


# top 3 acuracia em testes
melhores_acuracia_teste = resultados.nlargest(3, 'acuracia_teste')
print(melhores_acuracia_teste[['modelo', 'conjunto', 'acuracia_teste']])


# top 3 validação cruzada
melhores_acuracia_cv = resultados.nlargest(3, 'acuracia_cv')
print(melhores_acuracia_cv[['modelo', 'conjunto', 'acuracia_cv']])


# top 3 possivel overfiting
overfitting_potencial = resultados.nlargest(3, 'dif_acuracia_treino_teste')
print(overfitting_potencial[['modelo', 'conjunto', 'acuracia_teste', 'acuracia_treino', 'dif_acuracia_treino_teste']])


# top 3 f1_score
melhores_f1_score = resultados.nlargest(3, 'f1_score')
print(melhores_f1_score[['modelo', 'conjunto', 'f1_score']])


# top 3 precision
melhores_precision = resultados.nlargest(3, 'precision')
print(melhores_f1_score[['modelo', 'conjunto', 'precision']])


# top 3 recall
melhores_recall = resultados.nlargest(3, 'recall')
print(melhores_f1_score[['modelo', 'conjunto', 'recall']])


# melhor modelo
resultados[(resultados['modelo'] == 'XGBoost') & (resultados['conjunto'] == 'label_encoded')]


# export
resultados.to_csv('../data/results.csv', sep=',', index=False)
